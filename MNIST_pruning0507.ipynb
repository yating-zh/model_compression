{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpuPv7v5jYXq3ay9+oePpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yating-zh/model_compression/blob/main/MNIST_pruning0507.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch  torchvision==0.16.0 torchaudio==2.1.0\n",
        "\n",
        "# An error must downgrade to torch 2.1.0\n",
        "# AttributeError: 'NoneType' object has no attribute 'startswith' at the SpeedUp step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h-D6eeXlW02w",
        "outputId": "a1f1f7e5-04dc-429a-a211-24f92a8df452"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting torchvision==0.16.0\n",
            "  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.0\n",
            "  Downloading torchaudio-2.1.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (2.31.0)\n",
            "Collecting torch\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.1.0 (from torch)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.2.1+cu121\n",
            "    Uninstalling torchaudio-2.2.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 torchaudio-2.1.0 torchvision-0.16.0 triton-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision"
                ]
              },
              "id": "78fdd9507f6a4d6c87489f4882e1b88e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nni"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSJgIRT_DD6F",
        "outputId": "9a834608-8a00-4c2c-bbe5-63843bae850b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nni in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from nni) (0.8.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from nni) (2.2.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from nni) (0.4.6)\n",
            "Requirement already satisfied: filelock<3.12 in /usr/local/lib/python3.10/dist-packages (from nni) (3.11.0)\n",
            "Requirement already satisfied: json-tricks>=3.15.5 in /usr/local/lib/python3.10/dist-packages (from nni) (3.17.3)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from nni) (12.550.52)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nni) (24.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nni) (2.0.3)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from nni) (3.10.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nni) (5.9.5)\n",
            "Requirement already satisfied: PythonWebHDFS in /usr/local/lib/python3.10/dist-packages (from nni) (0.2.3)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from nni) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nni) (2.31.0)\n",
            "Requirement already satisfied: responses in /usr/local/lib/python3.10/dist-packages (from nni) (0.25.0)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.10/dist-packages (from nni) (0.7.7)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from nni) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nni) (4.66.2)\n",
            "Requirement already satisfied: typeguard<4.1.3,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nni) (4.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from nni) (4.11.0)\n",
            "Requirement already satisfied: websockets>=10.1 in /usr/local/lib/python3.10/dist-packages (from nni) (12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nni) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nni) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->nni) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->nni) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2024.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->nni) (0.2.13)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from PythonWebHDFS->nni) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->nni) (1.16.0)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pytorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.optim import SGD\n",
        "from nni.compression.pruning import L1NormPruner\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooMe0wlkCIFi",
        "outputId": "ba767a33-c816-4a80-fae6-5682b8babd90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Pretrain a model using MNIST dataset"
      ],
      "metadata": {
        "id": "9U9f86OwB1LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional to run code on GPU\n",
        "# Check if CUDA is available and if device is GPU\n",
        "print('Cuda Available : {}'.format(torch.cuda.is_available()))\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU - {0}'.format(torch.cuda.get_device_name()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktaknu79CEq2",
        "outputId": "c043bf3f-0c8d-499d-a278-00789bf4a90b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda Available : True\n",
            "GPU - Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model,\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 3\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# Data loader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define a convolutional neural network model for MNIST\n",
        "class TorchModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TorchModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # Adjusted to match output of conv2\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu2(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.relu4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = TorchModel().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DNtXIrgGURC",
        "outputId": "b2bc9499-b71b-46b4-dd92-ad59b3156c48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TorchModel(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (relu2): ReLU()\n",
            "  (relu3): ReLU()\n",
            "  (relu4): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sava the model before compression\n",
        "torch.save(model.state_dict(), 'original_model.pth')"
      ],
      "metadata": {
        "id": "4apYXoahYByC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Function to train the model\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Training and evaluation loop\n",
        "for epoch in range(num_epochs):\n",
        "    train(model, train_loader, optimizer, criterion)\n",
        "    evaluate(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw5jrks0QCS2",
        "outputId": "34b5a480-fea0-4d9e-87fa-f6a3a42565fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 57.70%\n",
            "Accuracy: 91.18%\n",
            "Accuracy: 94.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pruning configuration\n",
        "config_list = [{\n",
        "    'op_types': ['Linear', 'Conv2d'],\n",
        "    'exclude_op_names': ['fc3'],\n",
        "    'sparse_ratio': 0.5\n",
        "}]\n",
        "\n",
        "# Apply L1NormPruner\n",
        "pruner = L1NormPruner(model, config_list)\n",
        "# model = pruner.compress()[0]\n",
        "# print(pruner)\n",
        "# print(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "5yIpHlTdRkC-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compress the model and generate the masks\n",
        "_, masks = pruner.compress()\n",
        "# show the masks sparsity\n",
        "for name, mask in masks.items():\n",
        "    print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyivupyKG32Q",
        "outputId": "82f03f75-a3b8-4d64-9e00-89eec688d318"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv2  sparsity :  0.5\n",
            "conv1  sparsity :  0.5\n",
            "fc1  sparsity :  0.5\n",
            "fc2  sparsity :  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need to unwrap the model, if the model is wrapped before speedup\n",
        "pruner.unwrap_model()\n",
        "\n",
        "# speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
        "from nni.compression.speedup import ModelSpeedup\n",
        "# from nni.compression.torch import ModelSpeedup\n",
        "\n",
        "\n",
        "m_speedup = ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks)\n",
        "m_speedup.speedup_model()\n",
        "\n",
        "\n",
        "# ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()\n",
        "# (3, 1, 28, 28) in the code represents the dimensions of a tensor\n",
        "\n",
        "# 3: The number of data samples in the batch. This means that the input consists of 3 separate images being processed simultaneously.\n",
        "# 1: The number of channels in each image. For grayscale images, such as those typically used in the MNIST dataset, this number is 1. If it were a color image in a standard RGB format, this number would be 3.\n",
        "# 28, 28: The dimensions of each image. In the case of the MNIST dataset, each image is 28 pixels wide by 28 pixels high.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHmZoOmCG8ZO",
        "outputId": "1dc5adbf-5708-406a-b240-6e11f1849054"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mStart to speedup the model...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Start to speedup the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Resolve the mask conflict before mask propagate...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim0 sparsity: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim1 sparsity: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Filter\n",
            "[2024-05-07 09:24:48] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim0 sparsity: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim1 sparsity: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mInfer module masks...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Infer module masks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate original variables\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate original variables\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for placeholder: x, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: relu1, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: relu1, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: pool1, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: pool1, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: relu2, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: relu2, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: pool2, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: pool2, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_method: view, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_method: view, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: relu3, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: relu3, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: relu4, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: relu4, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for call_module: fc3, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: fc3, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for output: output, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct sparsity...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct sparsity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for placeholder: x, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: relu1, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: relu1, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: pool1, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: pool1, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: relu2, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: relu2, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: pool2, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: pool2, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_method: view, output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_method: view, output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: relu3, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: relu3, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: relu4, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: relu4, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: fc3, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for output: output, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect sparsity...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect sparsity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for output: output, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: fc3, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: relu4, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: relu4, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: fc2, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: fc2, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: relu3, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: relu3, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: fc1, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: fc1, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_method: view, output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_method: view, output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: pool2, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: pool2, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: relu2, , output mask:  0.5498 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: relu2, , output mask:  0.5498 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: conv2, weight:  0.7500 bias:  0.5000 , output mask:  0.5498 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: conv2, weight:  0.7500 bias:  0.5000 , output mask:  0.5498 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: pool1, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: pool1, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:48] \u001b[32mUpdate indirect mask for call_module: relu1, , output mask:  0.5486 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: relu1, , output mask:  0.5486 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mUpdate indirect mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5486 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5486 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for placeholder: x, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Resolve the mask conflict after mask propagate...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim0 sparsity: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mdim1 sparsity: 0.428571\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim1 sparsity: 0.428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:nni.compression.speedup.mask_conflict:both dim0 and dim1 masks found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Filter\n",
            "[2024-05-07 09:24:49] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim0 sparsity: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mdim1 sparsity: 0.428571\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim1 sparsity: 0.428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:nni.compression.speedup.mask_conflict:both dim0 and dim1 masks found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mReplace compressed modules...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Replace compressed modules...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: conv1, op_type: Conv2d)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace conv2d with in_channels: 1, out_channels: 3\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace conv2d with in_channels: 1, out_channels: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: relu1, op_type: ReLU)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: relu1, op_type: ReLU)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: pool1, op_type: MaxPool2d)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: pool1, op_type: MaxPool2d)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: conv2, op_type: Conv2d)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace conv2d with in_channels: 3, out_channels: 8\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace conv2d with in_channels: 3, out_channels: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: relu2, op_type: ReLU)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: relu2, op_type: ReLU)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: pool2, op_type: MaxPool2d)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: pool2, op_type: MaxPool2d)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: fc1, op_type: Linear)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace linear with new in_features: 128, out_features: 60\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace linear with new in_features: 128, out_features: 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: relu3, op_type: ReLU)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: relu3, op_type: ReLU)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: fc2, op_type: Linear)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace linear with new in_features: 60, out_features: 42\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace linear with new in_features: 60, out_features: 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: relu4, op_type: ReLU)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: relu4, op_type: ReLU)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace module (name: fc3, op_type: Linear)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: fc3, op_type: Linear)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mreplace linear with new in_features: 42, out_features: 10\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace linear with new in_features: 42, out_features: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-07 09:24:49] \u001b[32mSpeedup done.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Speedup done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TorchModel(\n",
              "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=128, out_features=60, bias=True)\n",
              "  (fc2): Linear(in_features=60, out_features=42, bias=True)\n",
              "  (fc3): Linear(in_features=42, out_features=10, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (relu2): ReLU()\n",
              "  (relu3): ReLU()\n",
              "  (relu4): ReLU()\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "# 这里是pruned model， 经过prunning：\n",
        "# layer的数量和layer的类型都没有变化\n",
        "# 但是由于prune掉了一些weights，所以layer的output weights的个数有减少，也是因此，TorchModel()变了，因此最后要测量eval就需要重新定义TorchModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDMjHPkDSi-",
        "outputId": "c46d1657-a652-49ba-bd99-4401ad8e1d1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TorchModel(\n",
            "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=128, out_features=60, bias=True)\n",
            "  (fc2): Linear(in_features=60, out_features=42, bias=True)\n",
            "  (fc3): Linear(in_features=42, out_features=10, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (relu2): ReLU()\n",
            "  (relu3): ReLU()\n",
            "  (relu4): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sava the model after compression\n",
        "torch.save(model.state_dict(), 'compressed_model.pth')"
      ],
      "metadata": {
        "id": "VJ_RhvpQX5nh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Pruning model using NNI library (compression)"
      ],
      "metadata": {
        "id": "bT3sg4jMDMd8"
      }
    }
  ]
}