{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooMe0wlkCIFi",
    "outputId": "3573bdc0-41bb-491a-ab51-f7a6bb45d725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nni in /Users/yating/nni (999.dev0)\n",
      "Requirement already satisfied: astor in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/astor-0.8.1-py3.10.egg (from nni) (0.8.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (3.0.0)\n",
      "Requirement already satisfied: colorama in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (0.4.6)\n",
      "Requirement already satisfied: filelock<3.12 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (3.11.0)\n",
      "Requirement already satisfied: json_tricks>=3.15.5 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/json_tricks-3.17.3-py3.10.egg (from nni) (3.17.3)\n",
      "Requirement already satisfied: nvidia-ml-py in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/nvidia_ml_py-12.550.52-py3.10.egg (from nni) (12.550.52)\n",
      "Requirement already satisfied: packaging in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (23.2)\n",
      "Requirement already satisfied: pandas in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (2.2.0)\n",
      "Requirement already satisfied: prettytable in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/prettytable-3.10.0-py3.10.egg (from nni) (3.10.0)\n",
      "Requirement already satisfied: psutil in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (5.9.8)\n",
      "Requirement already satisfied: PythonWebHDFS in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/PythonWebHDFS-0.2.3-py3.10.egg (from nni) (0.2.3)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (2.31.0)\n",
      "Requirement already satisfied: responses in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/responses-0.25.0-py3.10.egg (from nni) (0.25.0)\n",
      "Requirement already satisfied: schema in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/schema-0.7.7-py3.10.egg (from nni) (0.7.7)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (1.4.0)\n",
      "Requirement already satisfied: tqdm in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (4.66.1)\n",
      "Requirement already satisfied: typeguard<4.1.3,>=3.0.0 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/typeguard-4.1.2-py3.10.egg (from nni) (4.1.2)\n",
      "Requirement already satisfied: typing_extensions>=4.7.0 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (4.9.0)\n",
      "Requirement already satisfied: websockets>=10.1 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/websockets-12.0-py3.10-macosx-11.0-arm64.egg (from nni) (12.0)\n",
      "Requirement already satisfied: numpy in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from nni) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn>=0.24.1->nni) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn>=0.24.1->nni) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas->nni) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas->nni) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas->nni) (2023.4)\n",
      "Requirement already satisfied: wcwidth in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from prettytable->nni) (0.2.13)\n",
      "Requirement already satisfied: simplejson in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages/simplejson-3.19.2-py3.10-macosx-11.0-arm64.egg (from PythonWebHDFS->nni) (3.19.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->nni) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->nni) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->nni) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->nni) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yating/miniconda3/envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->nni) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooMe0wlkCIFi",
    "outputId": "3573bdc0-41bb-491a-ab51-f7a6bb45d725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# import pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD\n",
    "from nni.compression.pruning import L1NormPruner\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U9f86OwB1LX"
   },
   "source": [
    "## 1. Pretrain a model using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktaknu79CEq2",
    "outputId": "1081648e-981e-4b16-809d-70dc565a8817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Available : False\n"
     ]
    }
   ],
   "source": [
    "# Optional to run code on GPU\n",
    "# Check if CUDA is available and if device is GPU\n",
    "print('Cuda Available : {}'.format(torch.cuda.is_available()))\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU - {0}'.format(torch.cuda.get_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DNtXIrgGURC",
    "outputId": "d046ba7e-787e-4db8-e6df-ce595cdde5e7"
   },
   "outputs": [],
   "source": [
    "# # Define the CNN model,\n",
    "\n",
    "\n",
    "# # Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Hyperparameters\n",
    "# num_epochs = 3\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.01\n",
    "\n",
    "# # MNIST dataset\n",
    "# train_dataset = datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "# test_dataset = datasets.MNIST(root='data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# # Data loader\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Define a convolutional neural network model for MNIST\n",
    "# class TorchModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TorchModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "#         self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "#         self.fc1 = nn.Linear(16 * 4 * 4, 120)  # Adjusted to match output of conv2\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.relu4 = nn.ReLU()\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.conv1(x))\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.relu2(self.conv2(x))\n",
    "#         x = self.pool2(x)\n",
    "#         x = x.view(-1, 16 * 4 * 4)\n",
    "#         x = self.relu3(self.fc1(x))\n",
    "#         x = self.relu4(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         x = F.log_softmax(x, dim=1)  # Add this line\n",
    "#         return x\n",
    "\n",
    "# model = TorchModel().to(device)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (relu4): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# test initialise the 16,4,4\n",
    "# Define the CNN model,\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define a convolutional neural network model for MNIST\n",
    "class TorchModel(nn.Module):\n",
    "    def __init__(self, v1=16, v2=4, v3=4):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.v1 = v1  # Typically the number of output channels from the last conv layer\n",
    "        self.v2 = v2  # Height of the feature map\n",
    "        self.v3 = v3  # Width of the feature map\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "        self.fc1 = nn.Linear(self.v1 * self.v2 * self.v3, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     x = self.relu1(self.conv1(x))\n",
    "    #     x = self.pool1(x)\n",
    "    #     x = self.relu2(self.conv2(x))\n",
    "    #     x = self.pool2(x)\n",
    "    #     x = x.view(-1, self.v1 * self.v2 * self.v3)  # Use the dynamically set values\n",
    "    #     x = self.relu3(self.fc1(x))\n",
    "    #     x = self.relu4(self.fc2(x))\n",
    "    #     x = self.fc3(x)\n",
    "    #     x = F.log_softmax(x, dim=1)\n",
    "    #     return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        # Dynamically calculate the correct number of features for flattening\n",
    "        x = x.view(x.size(0), -1)  # Automatically calculate the correct number of features\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = TorchModel(16, 4, 4).to(device)  # Original model dimensions\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_original_visualization.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchviz\n",
    "\n",
    "# Run the model forward pass and visualize using torchviz:\n",
    "from torchviz import make_dot\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "dummy_input = torch.randn(3, 1, 28, 28)\n",
    "\n",
    "# Run a forward pass with the dummy input to get the output tensor\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Generate the graph using torchviz\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "\n",
    "# To display in Jupyter Notebook/JupyterLab\n",
    "# dot.view()\n",
    "# Saves the visualization as a PNG file\n",
    "dot.render('model_original_visualization', format='png')  # Saves the visualization as a PNG file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4apYXoahYByC"
   },
   "outputs": [],
   "source": [
    "# sava the model before compression\n",
    "torch.save(model.state_dict(), 'original_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lw5jrks0QCS2",
    "outputId": "3341f716-80ea-487a-a87a-fc8d5cda6eec"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function to train the model\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            total_loss += loss.item() * data.size(0)  # Multiply loss by batch size to get total loss for batch\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    average_loss = total_loss / total\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8702, Accuracy: 72.23%\n",
      "Loss: 0.3166, Accuracy: 90.51%\n",
      "Loss: 0.2490, Accuracy: 92.12%\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Training and evaluation loop\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, optimizer, criterion)\n",
    "    # evaluate(model, test_loader)\n",
    "    evaluate(model, test_loader, criterion)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "total_time_original = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5yIpHlTdRkC-"
   },
   "outputs": [],
   "source": [
    "# Pruning configuration\n",
    "config_list = [{\n",
    "    'op_types': ['Linear', 'Conv2d'],\n",
    "    'exclude_op_names': ['fc3'],\n",
    "    'sparse_ratio': 0.5\n",
    "}]\n",
    "\n",
    "# Apply L1NormPruner\n",
    "pruner = L1NormPruner(model, config_list)\n",
    "# model = pruner.compress()[0]\n",
    "# print(pruner)\n",
    "# print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyivupyKG32Q",
    "outputId": "dda51f61-d769-4234-de94-e7b615837bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2  sparsity :  0.5\n",
      "fc1  sparsity :  0.5\n",
      "fc2  sparsity :  0.5\n",
      "conv1  sparsity :  0.5\n"
     ]
    }
   ],
   "source": [
    "# compress the model and generate the masks\n",
    "_, masks = pruner.compress()\n",
    "# show the masks sparsity\n",
    "for name, mask in masks.items():\n",
    "    print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHmZoOmCG8ZO",
    "outputId": "760f23ae-af07-4c67-a816-7289f9eb295d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-08 00:53:49] \u001b[32mStart to speedup the model...\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "0 Filter\n",
      "[2024-05-08 00:53:49] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mInfer module masks...\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate original variables\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: relu1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: pool1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: relu2, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: pool2, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_method: size, \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_method: view, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: relu3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: relu4, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct sparsity...\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: relu1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: pool1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: relu2, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: pool2, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_method: size, \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_method: view, output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: relu3, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: relu4, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect sparsity...\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: relu4, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: fc2, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: relu3, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: fc1, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_method: view, output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_method: size, \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: pool2, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: relu2, , output mask:  0.5479 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: conv2, weight:  0.7500 bias:  0.5000 , output mask:  0.5479 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: pool1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: relu1, , output mask:  0.5480 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5480 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mdim1 sparsity: 0.428571\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "0 Filter\n",
      "[2024-05-08 00:53:49] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mdim1 sparsity: 0.428571\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mReplace compressed modules...\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace conv2d with in_channels: 1, out_channels: 3\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: relu1, op_type: ReLU)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: pool1, op_type: MaxPool2d)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace conv2d with in_channels: 3, out_channels: 8\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: relu2, op_type: ReLU)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: pool2, op_type: MaxPool2d)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace linear with new in_features: 128, out_features: 60\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: relu3, op_type: ReLU)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace linear with new in_features: 60, out_features: 42\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: relu4, op_type: ReLU)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace module (name: fc3, op_type: Linear)\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mreplace linear with new in_features: 42, out_features: 10\u001b[0m\n",
      "[2024-05-08 00:53:49] \u001b[32mSpeedup done.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchModel(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=128, out_features=60, bias=True)\n",
       "  (fc2): Linear(in_features=60, out_features=42, bias=True)\n",
       "  (fc3): Linear(in_features=42, out_features=10, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (relu2): ReLU()\n",
       "  (relu3): ReLU()\n",
       "  (relu4): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to unwrap the model, if the model is wrapped before speedup\n",
    "pruner.unwrap_model()\n",
    "\n",
    "# speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
    "from nni.compression.speedup import ModelSpeedup\n",
    "\n",
    "m_speedup = ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks)\n",
    "m_speedup.speedup_model()\n",
    "\n",
    "\n",
    "# ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()\n",
    "# (3, 1, 28, 28) in the code represents the dimensions of a tensor\n",
    "\n",
    "# 3: The number of data samples in the batch. This means that the input consists of 3 separate images being processed simultaneously.\n",
    "# 1: The number of channels in each image. For grayscale images, such as those typically used in the MNIST dataset, this number is 1. If it were a color image in a standard RGB format, this number would be 3.\n",
    "# 28, 28: The dimensions of each image. In the case of the MNIST dataset, each image is 28 pixels wide by 28 pixels high.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JDMjHPkDSi-",
    "outputId": "3bb26c71-a482-4c6f-9d78-f5e91f9f5b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=60, bias=True)\n",
      "  (fc2): Linear(in_features=60, out_features=42, bias=True)\n",
      "  (fc3): Linear(in_features=42, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (relu4): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "# 这里是pruned model， 经过prunning：\n",
    "# layer的数量和layer的类型都没有变化\n",
    "# 但是由于prune掉了一些weights，所以layer的output weights的个数有减少，也是因此，TorchModel()变了，因此最后要测量eval就需要重新定义TorchModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_pruned_visualization.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "dummy_input = torch.randn(2, 1, 28, 28)\n",
    "\n",
    "# Run a forward pass with the dummy input to get the output tensor\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Generate the graph using torchviz\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "\n",
    "# To display in Jupyter Notebook/JupyterLab\n",
    "# dot.view()\n",
    "# Saves the visualization as a PNG file\n",
    "dot.render('model_pruned_visualization', format='png')  # Saves the visualization as a PNG file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bT3sg4jMDMd8"
   },
   "source": [
    "## Fine-tuning Compacted Model\n",
    "Note that if the model has been sped up, you need to re-initialize a new optimizer for fine-tuning.\n",
    "Because speedup will replace the masked big layers with dense small ones.\n",
    ">After pruning and speedup, the model is typically smaller and faster, but it may also lose some accuracy or require adjustment to fully adapt to its new structure, which is where fine-tuning comes in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dYQMlJkj-oAM"
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "0osyIhHF-oSV",
    "outputId": "868a8176-27c4-4957-c38a-bca8d59f3afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1888, Accuracy: 94.15%\n",
      "Loss: 0.1547, Accuracy: 95.37%\n",
      "Loss: 0.1189, Accuracy: 96.24%\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning loop for the pruned model\n",
    "optimizer = SGD(model.parameters(), 1e-2) # 0.01 is the learning rate\n",
    "criterion = F.nll_loss\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, optimizer, criterion)\n",
    "    # evaluate(model, test_loader)\n",
    "    evaluate(model, test_loader, criterion)\n",
    "\n",
    "\n",
    "\n",
    "# from nni_assets.compression.mnist_model import TorchModel, trainer, evaluator, device\n",
    "# optimizer = SGD(model.parameters(), 1e-2) # 0.01 is the learning rate\n",
    "# criterion = F.nll_loss\n",
    "# for epoch in range(3):\n",
    "#     trainer(model, optimizer, criterion)\n",
    "#     evaluator(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lzzQSI3b-oYj"
   },
   "outputs": [],
   "source": [
    "# End timing\n",
    "end_time = time.time()\n",
    "total_time_compressed = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cof78cw9-cCD"
   },
   "outputs": [],
   "source": [
    "# sava the model after compression\n",
    "torch.save(model.state_dict(), 'compressed_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Validation: Model compression\n",
    "\n",
    "\n",
    "1. the model size\n",
    "2. execution time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. the model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Size: 181466 bytes\n",
      "Compressed Model Size: 49334 bytes\n",
      "Reduction in Size: 132132 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "size_original = os.path.getsize('original_model.pth')\n",
    "size_compressed = os.path.getsize('compressed_model.pth')\n",
    "print(f'Original Model Size: {size_original} bytes')\n",
    "print(f'Compressed Model Size: {size_compressed} bytes')\n",
    "print(f'Reduction in Size: {size_original - size_compressed} bytes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Execution Time: 37.83460831642151 (s)\n",
      "Compressed Model Execution Time: 34.30511403083801 (s)\n",
      "Reduction in Execution Time: 3.529494285583496 (s)\n"
     ]
    }
   ],
   "source": [
    "training_time_reduction=total_time_original-total_time_compressed\n",
    "print(f'Original Model Execution Time: {total_time_original} (s)')\n",
    "print(f'Compressed Model Execution Time: {total_time_compressed} (s)')\n",
    "print(f'Reduction in Execution Time: {training_time_reduction} (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
