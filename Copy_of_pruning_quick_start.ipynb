{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yating-zh/model_compression/blob/main/Copy_of_pruning_quick_start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG3A5zkP3o_z"
      },
      "source": [
        "\n",
        "# Pruning Quickstart\n",
        "\n",
        "Model pruning is a technique to reduce the model size and computation by reducing model weight size or intermediate state size.\n",
        "There are three common practices for pruning a DNN model:\n",
        "\n",
        "#. Pre-training a model -> Pruning the model -> Fine-tuning the pruned model\n",
        "#. Pruning a model during training (i.e., pruning aware training) -> Fine-tuning the pruned model\n",
        "#. Pruning a model -> Training the pruned model from scratch\n",
        "\n",
        "NNI supports all of the above pruning practices by working on the key pruning stage.\n",
        "Following this tutorial for a quick look at how to use NNI to prune a model in a common practice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h20pcWtv3o_1"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "In this tutorial, we use a simple model and pre-trained on MNIST dataset.\n",
        "If you are familiar with defining a model and training in pytorch, you can skip directly to `Pruning Model`_.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downgrade the Python version to 2.1.0. Otherwise the Speedup does not work.\n",
        "!pip install torch  torchvision==0.16.0 torchaudio==2.1.0 pytorch-cuda==12.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh3GHkQkTrRL",
        "outputId": "7e20f04d-7c8b-4c9d-9d6f-d66800265edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torchvision==0.16.0 in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: torchaudio==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: pytorch-cuda==12.1 in /usr/local/lib/python3.10/dist-packages (12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (10.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install nni (Neural Network Intelligence)\n",
        "! pip install nni"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rNypc7b-ubB",
        "outputId": "52b125a6-265b-40ad-d529-06feeccbd965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nni in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from nni) (0.8.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from nni) (2.2.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from nni) (0.4.6)\n",
            "Requirement already satisfied: filelock<3.12 in /usr/local/lib/python3.10/dist-packages (from nni) (3.11.0)\n",
            "Requirement already satisfied: json-tricks>=3.15.5 in /usr/local/lib/python3.10/dist-packages (from nni) (3.17.3)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from nni) (12.550.52)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nni) (24.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nni) (2.0.3)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from nni) (3.10.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nni) (5.9.5)\n",
            "Requirement already satisfied: PythonWebHDFS in /usr/local/lib/python3.10/dist-packages (from nni) (0.2.3)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from nni) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nni) (2.31.0)\n",
            "Requirement already satisfied: responses in /usr/local/lib/python3.10/dist-packages (from nni) (0.25.0)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.10/dist-packages (from nni) (0.7.7)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from nni) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nni) (4.66.2)\n",
            "Requirement already satisfied: typeguard<4.1.3,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nni) (4.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from nni) (4.11.0)\n",
            "Requirement already satisfied: websockets>=10.1 in /usr/local/lib/python3.10/dist-packages (from nni) (12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nni) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nni) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->nni) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->nni) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nni) (2024.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->nni) (0.2.13)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from PythonWebHDFS->nni) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nni) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->nni) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gYfgrzO3o_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9956888d-f7da-4952-a662-64b7c5eaebcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TorchModel(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (relu2): ReLU()\n",
            "  (relu3): ReLU()\n",
            "  (relu4): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "\n",
        "from nni_assets.compression.mnist_model import TorchModel, trainer, evaluator, device\n",
        "\n",
        "# define the model\n",
        "model = TorchModel().to(device)\n",
        "\n",
        "# show the model structure, note that pruner will wrap the model layer.\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sava the model before compression\n",
        "torch.save(model.state_dict(), 'original_model.pth')"
      ],
      "metadata": {
        "id": "qTFtHxsogNbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbEmMsEx3o_1"
      },
      "outputs": [],
      "source": [
        "# define the optimizer and criterion for pre-training\n",
        "\n",
        "optimizer = SGD(model.parameters(), 1e-2) # 0.01 is the learning rate\n",
        "criterion = F.nll_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start timing\n",
        "import time\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "29VO_Tgorje5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-train and evaluate the model on MNIST dataset\n",
        "for epoch in range(3):\n",
        "    trainer(model, optimizer, criterion)\n",
        "    evaluator(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg24r_a0rlWD",
        "outputId": "3047f3b2-20ac-4437-826a-4b04d90b4a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average test loss: 0.5561, Accuracy: 8485/10000 (85%)\n",
            "Average test loss: 0.2397, Accuracy: 9281/10000 (93%)\n",
            "Average test loss: 0.1655, Accuracy: 9495/10000 (95%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End timing\n",
        "end_time = time.time()\n",
        "total_time_original = end_time - start_time\n"
      ],
      "metadata": {
        "id": "wrhyo95-rmuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCXXtf4_3o_1"
      },
      "source": [
        "## Pruning Model\n",
        "\n",
        "Using L1NormPruner to prune the model and generate the masks.\n",
        "Usually, a pruner requires original model and ``config_list`` as its inputs.\n",
        "Detailed about how to write ``config_list`` please refer :doc:`compression config specification <../compression/config_list>`.\n",
        "\n",
        "The following `config_list` means all layers whose type is `Linear` or `Conv2d` will be pruned,\n",
        "except the layer named `fc3`, because `fc3` is `exclude`.\n",
        "The final sparsity ratio for each layer is 50%. The layer named `fc3` will not be pruned.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx1g1pAr3o_1"
      },
      "outputs": [],
      "source": [
        "config_list = [{\n",
        "    'op_types': ['Linear', 'Conv2d'],\n",
        "    'exclude_op_names': ['fc3'],\n",
        "    'sparse_ratio': 0.5\n",
        "}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKIkK64b3o_2"
      },
      "source": [
        "Pruners usually require `model` and `config_list` as input arguments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziqp9QT73o_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f5be70-2a9a-4b14-b16c-f9be1e393dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TorchModel(\n",
            "  (conv1): Conv2d(\n",
            "    1, 6, kernel_size=(5, 5), stride=(1, 1)\n",
            "    (_nni_wrapper): ModuleWrapper(module=Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)), module_name=conv1)\n",
            "  )\n",
            "  (conv2): Conv2d(\n",
            "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
            "    (_nni_wrapper): ModuleWrapper(module=Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)), module_name=conv2)\n",
            "  )\n",
            "  (fc1): Linear(\n",
            "    in_features=256, out_features=120, bias=True\n",
            "    (_nni_wrapper): ModuleWrapper(module=Linear(in_features=256, out_features=120, bias=True), module_name=fc1)\n",
            "  )\n",
            "  (fc2): Linear(\n",
            "    in_features=120, out_features=84, bias=True\n",
            "    (_nni_wrapper): ModuleWrapper(module=Linear(in_features=120, out_features=84, bias=True), module_name=fc2)\n",
            "  )\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (relu2): ReLU()\n",
            "  (relu3): ReLU()\n",
            "  (relu4): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# create a wrapper, and in order to apply masks for each layer in that wrapper, 这里的pruner就是一个wrapper\n",
        "from nni.compression.pruning import L1NormPruner\n",
        "pruner = L1NormPruner(model, config_list) # pruner ~= wrapper\n",
        "\n",
        "\n",
        "# show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list.\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5S3hoG43o_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a0497a-c549-47ab-aa67-9f48d3143745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1  sparsity :  0.5\n",
            "conv1  sparsity :  0.5\n",
            "fc2  sparsity :  0.5\n",
            "conv2  sparsity :  0.5\n"
          ]
        }
      ],
      "source": [
        "# compress the model and generate the masks\n",
        "_, masks = pruner.compress()\n",
        "# show the masks sparsity\n",
        "for name, mask in masks.items():\n",
        "    print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo8pmKX-3o_2"
      },
      "source": [
        "Speedup the original model with masks, note that `ModelSpeedup` requires an unwrapped model.\n",
        "The model becomes smaller after speedup,\n",
        "and reaches a higher sparsity ratio because `ModelSpeedup` will propagate the masks across layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN6-Qkxz3o_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81909bcb-3574-4819-c3de-a7b62cefb64e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mStart to speedup the model...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Start to speedup the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Resolve the mask conflict before mask propagate...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim0 sparsity: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim1 sparsity: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Filter\n",
            "[2024-05-06 02:21:02] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim0 sparsity: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim1 sparsity: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mInfer module masks...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Infer module masks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate original variables\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate original variables\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for placeholder: x, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: relu1, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: relu1, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: pool1, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: pool1, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: relu2, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: relu2, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: pool2, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: pool2, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_function: flatten, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_function: flatten, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: relu3, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: relu3, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: relu4, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: relu4, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_module: fc3, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_module: fc3, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for call_function: log_softmax, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Propagate variables for output: output, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct sparsity...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct sparsity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for placeholder: x, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct mask for call_module: relu1, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: relu1, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct mask for call_module: pool1, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: pool1, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct mask for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: conv2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct mask for call_module: relu2, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: relu2, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct mask for call_module: pool2, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: pool2, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:02] \u001b[32mUpdate direct mask for call_function: flatten, output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_function: flatten, output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate direct mask for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: fc1, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate direct mask for call_module: relu3, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: relu3, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate direct mask for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: fc2, weight:  0.5000 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate direct mask for call_module: relu4, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: relu4, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate direct mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_module: fc3, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate direct mask for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for call_function: log_softmax, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update direct mask for output: output, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect sparsity...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect sparsity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for output: output, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_function: log_softmax, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_function: log_softmax, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: fc3, , output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: fc3, , output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: relu4, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: relu4, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: fc2, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: fc2, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: relu3, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: relu3, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: fc1, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: fc1, weight:  0.7500 bias:  0.5000 , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_function: flatten, output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_function: flatten, output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: pool2, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: pool2, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: relu2, , output mask:  0.5391 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: relu2, , output mask:  0.5391 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: conv2, weight:  0.7500 bias:  0.5000 , output mask:  0.5391 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: conv2, weight:  0.7500 bias:  0.5000 , output mask:  0.5391 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: pool1, , output mask:  0.5000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: pool1, , output mask:  0.5000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: relu1, , output mask:  0.5475 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: relu1, , output mask:  0.5475 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5475 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for call_module: conv1, weight:  0.5000 bias:  0.5000 , output mask:  0.5475 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Update indirect mask for placeholder: x, output mask:  0.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Resolve the mask conflict after mask propagate...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim0 sparsity: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mdim1 sparsity: 0.428571\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim1 sparsity: 0.428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:nni.compression.speedup.mask_conflict:both dim0 and dim1 masks found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Filter\n",
            "[2024-05-06 02:21:03] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim0 sparsity: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mdim1 sparsity: 0.428571\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.mask_conflict:dim1 sparsity: 0.428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:nni.compression.speedup.mask_conflict:both dim0 and dim1 masks found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mReplace compressed modules...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Replace compressed modules...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: conv1, op_type: Conv2d)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace conv2d with in_channels: 1, out_channels: 3\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace conv2d with in_channels: 1, out_channels: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: relu1, op_type: ReLU)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: relu1, op_type: ReLU)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: pool1, op_type: MaxPool2d)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: pool1, op_type: MaxPool2d)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: conv2, op_type: Conv2d)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace conv2d with in_channels: 3, out_channels: 8\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace conv2d with in_channels: 3, out_channels: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: relu2, op_type: ReLU)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: relu2, op_type: ReLU)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: pool2, op_type: MaxPool2d)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: pool2, op_type: MaxPool2d)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: fc1, op_type: Linear)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace linear with new in_features: 128, out_features: 60\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace linear with new in_features: 128, out_features: 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: relu3, op_type: ReLU)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: relu3, op_type: ReLU)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: fc2, op_type: Linear)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace linear with new in_features: 60, out_features: 42\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace linear with new in_features: 60, out_features: 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: relu4, op_type: ReLU)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: relu4, op_type: ReLU)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace module (name: fc3, op_type: Linear)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacer:replace module (name: fc3, op_type: Linear)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mreplace linear with new in_features: 42, out_features: 10\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.replacement:replace linear with new in_features: 42, out_features: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-06 02:21:03] \u001b[32mSpeedup done.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:nni.compression.speedup.model_speedup:Speedup done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TorchModel(\n",
              "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=128, out_features=60, bias=True)\n",
              "  (fc2): Linear(in_features=60, out_features=42, bias=True)\n",
              "  (fc3): Linear(in_features=42, out_features=10, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (relu2): ReLU()\n",
              "  (relu3): ReLU()\n",
              "  (relu4): ReLU()\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# need to unwrap the model, if the model is wrapped before speedup\n",
        "pruner.unwrap_model()\n",
        "\n",
        "# speedup the model, for more information about speedup, please refer :doc:`pruning_speedup`.\n",
        "from nni.compression.speedup import ModelSpeedup\n",
        "# from nni.compression.torch import ModelSpeedup\n",
        "\n",
        "\n",
        "m_speedup = ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks)\n",
        "m_speedup.speedup_model()\n",
        "\n",
        "\n",
        "# ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()\n",
        "# (3, 1, 28, 28) in the code represents the dimensions of a tensor\n",
        "\n",
        "# 3: The number of data samples in the batch. This means that the input consists of 3 separate images being processed simultaneously.\n",
        "# 1: The number of channels in each image. For grayscale images, such as those typically used in the MNIST dataset, this number is 1. If it were a color image in a standard RGB format, this number would be 3.\n",
        "# 28, 28: The dimensions of each image. In the case of the MNIST dataset, each image is 28 pixels wide by 28 pixels high.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNbaf-lP3o_2"
      },
      "source": [
        "the model will become real smaller after speedup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKfJ_fWd3o_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2badb6-ed35-4ad7-dacb-89e1c60df6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TorchModel(\n",
            "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=128, out_features=60, bias=True)\n",
            "  (fc2): Linear(in_features=60, out_features=42, bias=True)\n",
            "  (fc3): Linear(in_features=42, out_features=10, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (relu2): ReLU()\n",
            "  (relu3): ReLU()\n",
            "  (relu4): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)\n",
        "# 这里是pruned model， 经过prunning：\n",
        "# layer的数量和layer的类型都没有变化\n",
        "# 但是由于prune掉了一些weights，所以layer的output weights的个数有减少，也是因此，TorchModel()变了，因此最后要测量eval就需要重新定义TorchModel()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sava the model after compression\n",
        "torch.save(model.state_dict(), 'compressed_model.pth')"
      ],
      "metadata": {
        "id": "1OrKJz5NgTeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilRW7lUO3o_2"
      },
      "source": [
        "## Fine-tuning Compacted Model\n",
        "Note that if the model has been sped up, you need to re-initialize a new optimizer for fine-tuning.\n",
        "Because speedup will replace the masked big layers with dense small ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start timing\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "T5PYjyuvrWHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8MWX3wg3o_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795c1a3a-4bb6-41ee-b3ee-7f9e98113b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average test loss: 0.2120, Accuracy: 9388/10000 (94%)\n",
            "Average test loss: 0.1459, Accuracy: 9568/10000 (96%)\n",
            "Average test loss: 0.1438, Accuracy: 9558/10000 (96%)\n"
          ]
        }
      ],
      "source": [
        "optimizer = SGD(model.parameters(), 1e-2)\n",
        "for epoch in range(3):\n",
        "    trainer(model, optimizer, criterion)\n",
        "    evaluator(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End timing\n",
        "end_time = time.time()\n",
        "total_time_compressed = end_time - start_time\n"
      ],
      "metadata": {
        "id": "JJ9va1FbraD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Validation: Model compression\n",
        "1. the model size\n",
        "2. execution time\n"
      ],
      "metadata": {
        "id": "Q_9VM-1QgnSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. the model size"
      ],
      "metadata": {
        "id": "r0Z4aoA0sGdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "size_original = os.path.getsize('original_model.pth')\n",
        "size_compressed = os.path.getsize('compressed_model.pth')\n",
        "print(f'Original Model Size: {size_original} bytes')\n",
        "print(f'Compressed Model Size: {size_compressed} bytes')\n",
        "print(f'Reduction in Size: {size_original - size_compressed} bytes')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3_jRrlcgcxg",
        "outputId": "0857f4de-f8dd-42ea-c2ca-a1f815b2c152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Size: 181466 bytes\n",
            "Compressed Model Size: 49334 bytes\n",
            "Reduction in Size: 132132 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. execution time"
      ],
      "metadata": {
        "id": "jX7xO8MqsFhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_time_reduction=total_time_original-total_time_compressed\n",
        "print(f'Original Model Execution Time: {total_time_original} (s)')\n",
        "print(f'Compressed Model Execution Time: {total_time_compressed} (s)')\n",
        "print(f'Reduction in Execution Time: {training_time_reduction} (s)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXB61k8crwIH",
        "outputId": "72a01519-2898-4af1-f382-55fd380241ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Execution Time: 91.71007585525513 (s)\n",
            "Compressed Model Execution Time: 75.06762886047363 (s)\n",
            "Reduction in Execution Time: 16.642446994781494 (s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# execution time\n",
        "\n",
        "import time\n",
        "\n",
        "# Function to measure inference time\n",
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for data, _ in data_loader:\n",
        "            data = data.to(device)\n",
        "            _ = model(data)\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time\n",
        "\n",
        "# Assuming data_loader is defined and contains the MNIST test dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Prepare DataLoader for performance test\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "data_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "# Measure inference time before compression\n",
        "time_original = measure_inference_time(model, data_loader, device)\n",
        "\n",
        "# Load compressed model for testing\n",
        "\n",
        "# compressed_model = TorchModel().to(device)\n",
        "# compressed_model.load_state_dict(torch.load('compressed_model.pth'))\n",
        "\n"
      ],
      "metadata": {
        "id": "9LTG-87FhpLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model parameters as a dictionary\n",
        "model_params = {\n",
        "    \"conv1_out_channels\": 3,  # Adjusted output channels after compression\n",
        "    \"conv2_out_channels\": 8,\n",
        "    \"fc1_out_features\": 60,\n",
        "    \"fc2_out_features\": 42,\n",
        "    \"fc3_out_features\": 10\n",
        "}"
      ],
      "metadata": {
        "id": "5IYW3b14ot5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TorchModel(nn.Module):\n",
        "    def __init__(self, conv1_out_channels=6, conv2_out_channels=16, fc1_out_features=120, fc2_out_features=84, fc3_out_features=10):\n",
        "        super(TorchModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, conv1_out_channels, kernel_size=(5, 5), stride=(1, 1))\n",
        "        self.conv2 = nn.Conv2d(conv1_out_channels, conv2_out_channels, kernel_size=(5, 5), stride=(1, 1))\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Adjust input features based on the output from the last pool2 layer\n",
        "        self.fc1 = nn.Linear(conv2_out_channels * 4 * 4, fc1_out_features)\n",
        "        self.fc2 = nn.Linear(fc1_out_features, fc2_out_features)\n",
        "        self.fc3 = nn.Linear(fc2_out_features, fc3_out_features)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "compressed_model = TorchModel(\n",
        "    conv1_out_channels=model_params['conv1_out_channels'],\n",
        "    conv2_out_channels=model_params['conv2_out_channels'],\n",
        "    fc1_out_features=model_params['fc1_out_features'],\n",
        "    fc2_out_features=model_params['fc2_out_features'],\n",
        "    fc3_out_features=model_params['fc3_out_features']\n",
        ").to(device)\n",
        "\n",
        "\n",
        "compressed_model.load_state_dict(torch.load('compressed_model.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmJy8AvtmY_g",
        "outputId": "540758f0-f33a-424f-9115-915e88b026fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Measure inference time after compression\n",
        "time_compressed = measure_inference_time(compressed_model, data_loader, device)\n",
        "\n",
        "print(f'Original Inference Time: {time_original} seconds')\n",
        "print(f'Compressed Inference Time: {time_compressed} seconds')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXcXG_yEmZau",
        "outputId": "78dbb505-3acb-47a3-e31c-3033fa13a93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Inference Time: 2.6704070568084717 seconds\n",
            "Compressed Inference Time: 3.768873929977417 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}